# AI_voice-assistant
Here is the python notebook, a part of the project that I built for my dessertation (AI) project. The artefact of this project is a Gen AI Voice-Assistant with User-Accent-Replication practice. Over 300 hours have been invested in the research and development of this project, achieving 1st class score for the project report and demonstration.

- Developed an AI voice assistant using OpenAI's Whisper API for speech recognition and GPT-3.5-Turbo API for response generation, integrated with Google Cloud Text-to-Speech API for response delivery.
- Integrated an Artificial Neural Network (Tensorflow) model, with an impressive accuracy of 99.98%, to identify users' accents and respond in similar accents, enhancing the user experience for English speakers interacting with the Generative Pre-trained Transformer model.
- Technologies Used: Whisper API, GPT-3.5-Turbo API, Google Cloud Text-to-Speech API, Gradio by Hugging face, Jupyter, Tensorflow.
- Contributions: Led the end-to-end research and development, including API integration, accent recognition model implementation, and user experience enhancement.
- Outcomes: Improved accessibility of advanced language models like the GPT for English speakers across the world.

Data:
https://www.kaggle.com/datasets/imsparsh/accentdb-core-extended
